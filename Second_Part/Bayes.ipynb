{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn.naive_bayes as nB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Metacritic  Indie  Presence  Memory  ReleaseDate  Soundtrack  \\\n",
       "0    Very good  False     887.0   256.0       2008.0       False   \n",
       "1         Good   True  204071.0  2000.0       2014.0       False   \n",
       "2         Good  False   13512.0  2000.0       2016.0       False   \n",
       "3         Good  False  997391.0  6000.0       2017.0       False   \n",
       "4    Very good  False   75371.0  2000.0       2016.0       False   \n",
       "..         ...    ...       ...     ...          ...         ...   \n",
       "980       Good   True    1440.0  4000.0       2016.0       False   \n",
       "981       Good   True    1965.0   512.0       2011.0       False   \n",
       "982       Good  False    5410.0   128.0       2002.0       False   \n",
       "983       Good  False   59368.0  2000.0       2010.0       False   \n",
       "984       Good   True  538303.0  2000.0       2014.0       False   \n",
       "\n",
       "     OriginalCost  DiscountedCost  Controller  Achievements  ...  \\\n",
       "0           19.99             0.0       False           0.0  ...   \n",
       "1           19.99             0.0       False          79.0  ...   \n",
       "2           14.99             0.0       False          50.0  ...   \n",
       "3           39.99             0.0        True         141.0  ...   \n",
       "4           14.99             0.0        True          64.0  ...   \n",
       "..            ...             ...         ...           ...  ...   \n",
       "980          6.99             0.0       False           8.0  ...   \n",
       "981          4.99             0.0        True          21.0  ...   \n",
       "982          9.99             0.0       False           0.0  ...   \n",
       "983         24.99             0.0        True          63.0  ...   \n",
       "984         14.99             0.0        True         115.0  ...   \n",
       "\n",
       "     Platform-Mobile  Platform-PC  Platform-Xbox  Platform-PlayStation  \\\n",
       "0               True         True          False                 False   \n",
       "1              False         True          False                 False   \n",
       "2              False         True          False                 False   \n",
       "3              False         True           True                  True   \n",
       "4               True         True          False                  True   \n",
       "..               ...          ...            ...                   ...   \n",
       "980            False         True          False                 False   \n",
       "981            False         True          False                 False   \n",
       "982            False         True          False                 False   \n",
       "983            False         True          False                  True   \n",
       "984             True         True           True                  True   \n",
       "\n",
       "     Platform-Nintendo  Platform-Sega  RatingsBreakdown-Recommended  \\\n",
       "0                False          False                          12.0   \n",
       "1                False          False                           2.0   \n",
       "2                False          False                           4.0   \n",
       "3                False          False                          39.0   \n",
       "4                False          False                         113.0   \n",
       "..                 ...            ...                           ...   \n",
       "980              False          False                           1.0   \n",
       "981              False          False                           1.0   \n",
       "982              False          False                           8.0   \n",
       "983              False          False                          53.0   \n",
       "984               True          False                         114.0   \n",
       "\n",
       "     RatingsBreakdown-Meh  RatingsBreakdown-Exceptional  RatingsBreakdown-Skip  \n",
       "0                     9.0                           3.0                    7.0  \n",
       "1                     1.0                           NaN                    2.0  \n",
       "2                     1.0                           NaN                    1.0  \n",
       "3                    33.0                           6.0                   19.0  \n",
       "4                    49.0                          68.0                   35.0  \n",
       "..                    ...                           ...                    ...  \n",
       "980                   2.0                           NaN                    2.0  \n",
       "981                   1.0                           NaN                    3.0  \n",
       "982                   4.0                           1.0                    3.0  \n",
       "983                  22.0                          50.0                   13.0  \n",
       "984                  46.0                          25.0                   15.0  \n",
       "\n",
       "[985 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metacritic</th>\n      <th>Indie</th>\n      <th>Presence</th>\n      <th>Memory</th>\n      <th>ReleaseDate</th>\n      <th>Soundtrack</th>\n      <th>OriginalCost</th>\n      <th>DiscountedCost</th>\n      <th>Controller</th>\n      <th>Achievements</th>\n      <th>...</th>\n      <th>Platform-Mobile</th>\n      <th>Platform-PC</th>\n      <th>Platform-Xbox</th>\n      <th>Platform-PlayStation</th>\n      <th>Platform-Nintendo</th>\n      <th>Platform-Sega</th>\n      <th>RatingsBreakdown-Recommended</th>\n      <th>RatingsBreakdown-Meh</th>\n      <th>RatingsBreakdown-Exceptional</th>\n      <th>RatingsBreakdown-Skip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Very good</td>\n      <td>False</td>\n      <td>887.0</td>\n      <td>256.0</td>\n      <td>2008.0</td>\n      <td>False</td>\n      <td>19.99</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Good</td>\n      <td>True</td>\n      <td>204071.0</td>\n      <td>2000.0</td>\n      <td>2014.0</td>\n      <td>False</td>\n      <td>19.99</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>79.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Good</td>\n      <td>False</td>\n      <td>13512.0</td>\n      <td>2000.0</td>\n      <td>2016.0</td>\n      <td>False</td>\n      <td>14.99</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>50.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Good</td>\n      <td>False</td>\n      <td>997391.0</td>\n      <td>6000.0</td>\n      <td>2017.0</td>\n      <td>False</td>\n      <td>39.99</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>141.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>39.0</td>\n      <td>33.0</td>\n      <td>6.0</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Very good</td>\n      <td>False</td>\n      <td>75371.0</td>\n      <td>2000.0</td>\n      <td>2016.0</td>\n      <td>False</td>\n      <td>14.99</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>64.0</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>113.0</td>\n      <td>49.0</td>\n      <td>68.0</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>980</th>\n      <td>Good</td>\n      <td>True</td>\n      <td>1440.0</td>\n      <td>4000.0</td>\n      <td>2016.0</td>\n      <td>False</td>\n      <td>6.99</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>8.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>981</th>\n      <td>Good</td>\n      <td>True</td>\n      <td>1965.0</td>\n      <td>512.0</td>\n      <td>2011.0</td>\n      <td>False</td>\n      <td>4.99</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>21.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>982</th>\n      <td>Good</td>\n      <td>False</td>\n      <td>5410.0</td>\n      <td>128.0</td>\n      <td>2002.0</td>\n      <td>False</td>\n      <td>9.99</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>8.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>983</th>\n      <td>Good</td>\n      <td>False</td>\n      <td>59368.0</td>\n      <td>2000.0</td>\n      <td>2010.0</td>\n      <td>False</td>\n      <td>24.99</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>63.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>53.0</td>\n      <td>22.0</td>\n      <td>50.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>984</th>\n      <td>Good</td>\n      <td>True</td>\n      <td>538303.0</td>\n      <td>2000.0</td>\n      <td>2014.0</td>\n      <td>False</td>\n      <td>14.99</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>115.0</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>114.0</td>\n      <td>46.0</td>\n      <td>25.0</td>\n      <td>15.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>985 rows Ã— 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 623
    }
   ],
   "source": [
    "data = pd.read_csv('games_clean.csv')\n",
    "random = 24\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before Indie\n Series([], Name: Indie, dtype: bool)\nAfter Indie\n Series([], Name: Indie, dtype: bool)\nBefore Presence\n Series([], Name: Presence, dtype: float64)\nAfter Presence\n Series([], Name: Presence, dtype: float64)\nBefore Memory\n 5     NaN\n12    NaN\n21    NaN\n40    NaN\n51    NaN\n       ..\n898   NaN\n919   NaN\n924   NaN\n931   NaN\n975   NaN\nName: Memory, Length: 100, dtype: float64\nAfter Memory\n Series([], Name: Memory, dtype: float64)\nBefore ReleaseDate\n 522   NaN\n700   NaN\n756   NaN\n861   NaN\nName: ReleaseDate, dtype: float64\nAfter ReleaseDate\n Series([], Name: ReleaseDate, dtype: float64)\nBefore Soundtrack\n Series([], Name: Soundtrack, dtype: bool)\nAfter Soundtrack\n Series([], Name: Soundtrack, dtype: bool)\nBefore OriginalCost\n 78    NaN\n101   NaN\n112   NaN\n141   NaN\n163   NaN\n207   NaN\n212   NaN\n266   NaN\n342   NaN\n353   NaN\n384   NaN\n393   NaN\n398   NaN\n447   NaN\n490   NaN\n559   NaN\n565   NaN\n733   NaN\n736   NaN\n764   NaN\n817   NaN\n881   NaN\n890   NaN\n920   NaN\n940   NaN\nName: OriginalCost, dtype: float64\nAfter OriginalCost\n Series([], Name: OriginalCost, dtype: float64)\nBefore DiscountedCost\n Series([], Name: DiscountedCost, dtype: float64)\nAfter DiscountedCost\n Series([], Name: DiscountedCost, dtype: float64)\nBefore Controller\n Series([], Name: Controller, dtype: bool)\nAfter Controller\n Series([], Name: Controller, dtype: bool)\nBefore Achievements\n Series([], Name: Achievements, dtype: float64)\nAfter Achievements\n Series([], Name: Achievements, dtype: float64)\nBefore Storage\n 5     NaN\n21    NaN\n28    NaN\n34    NaN\n40    NaN\n       ..\n961   NaN\n964   NaN\n969   NaN\n975   NaN\n982   NaN\nName: Storage, Length: 184, dtype: float64\nAfter Storage\n Series([], Name: Storage, dtype: float64)\nBefore Platform-Mobile\n Series([], Name: Platform-Mobile, dtype: bool)\nAfter Platform-Mobile\n Series([], Name: Platform-Mobile, dtype: bool)\nBefore Platform-PC\n Series([], Name: Platform-PC, dtype: bool)\nAfter Platform-PC\n Series([], Name: Platform-PC, dtype: bool)\nBefore Platform-Xbox\n Series([], Name: Platform-Xbox, dtype: bool)\nAfter Platform-Xbox\n Series([], Name: Platform-Xbox, dtype: bool)\nBefore Platform-PlayStation\n Series([], Name: Platform-PlayStation, dtype: bool)\nAfter Platform-PlayStation\n Series([], Name: Platform-PlayStation, dtype: bool)\nBefore Platform-Nintendo\n Series([], Name: Platform-Nintendo, dtype: bool)\nAfter Platform-Nintendo\n Series([], Name: Platform-Nintendo, dtype: bool)\nBefore Platform-Sega\n Series([], Name: Platform-Sega, dtype: bool)\nAfter Platform-Sega\n Series([], Name: Platform-Sega, dtype: bool)\nBefore RatingsBreakdown-Recommended\n 17    NaN\n22    NaN\n23    NaN\n33    NaN\n57    NaN\n       ..\n922   NaN\n923   NaN\n942   NaN\n970   NaN\n974   NaN\nName: RatingsBreakdown-Recommended, Length: 89, dtype: float64\nAfter RatingsBreakdown-Recommended\n Series([], Name: RatingsBreakdown-Recommended, dtype: float64)\nBefore RatingsBreakdown-Meh\n 23    NaN\n33    NaN\n57    NaN\n82    NaN\n95    NaN\n96    NaN\n120   NaN\n136   NaN\n141   NaN\n148   NaN\n179   NaN\n199   NaN\n206   NaN\n210   NaN\n239   NaN\n250   NaN\n315   NaN\n323   NaN\n335   NaN\n346   NaN\n349   NaN\n361   NaN\n380   NaN\n426   NaN\n439   NaN\n471   NaN\n478   NaN\n488   NaN\n520   NaN\n559   NaN\n579   NaN\n587   NaN\n594   NaN\n610   NaN\n622   NaN\n641   NaN\n671   NaN\n681   NaN\n698   NaN\n720   NaN\n729   NaN\n737   NaN\n748   NaN\n754   NaN\n760   NaN\n770   NaN\n803   NaN\n805   NaN\n831   NaN\n833   NaN\n867   NaN\n869   NaN\n883   NaN\n906   NaN\n911   NaN\n941   NaN\n942   NaN\n970   NaN\n974   NaN\nName: RatingsBreakdown-Meh, dtype: float64\nAfter RatingsBreakdown-Meh\n Series([], Name: RatingsBreakdown-Meh, dtype: float64)\nBefore RatingsBreakdown-Exceptional\n 1     NaN\n2     NaN\n17    NaN\n22    NaN\n23    NaN\n       ..\n970   NaN\n976   NaN\n978   NaN\n980   NaN\n981   NaN\nName: RatingsBreakdown-Exceptional, Length: 225, dtype: float64\nAfter RatingsBreakdown-Exceptional\n Series([], Name: RatingsBreakdown-Exceptional, dtype: float64)\nBefore RatingsBreakdown-Skip\n 11    NaN\n15    NaN\n17    NaN\n22    NaN\n23    NaN\n       ..\n921   NaN\n923   NaN\n945   NaN\n967   NaN\n970   NaN\nName: RatingsBreakdown-Skip, Length: 118, dtype: float64\nAfter RatingsBreakdown-Skip\n Series([], Name: RatingsBreakdown-Skip, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "for name in data.columns[1:]:\n",
    "    print(\"Before\", name + '\\n', data[data[name].isna()][name])\n",
    "    data[name].fillna(data[name].mean(), inplace=True)\n",
    "    print(\"After\", name + '\\n', data[data[name].isna()][name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Metacritic                      0\n",
       "Indie                           0\n",
       "Presence                        0\n",
       "Memory                          0\n",
       "ReleaseDate                     0\n",
       "Soundtrack                      0\n",
       "OriginalCost                    0\n",
       "DiscountedCost                  0\n",
       "Controller                      0\n",
       "Achievements                    0\n",
       "Storage                         0\n",
       "Platform-Mobile                 0\n",
       "Platform-PC                     0\n",
       "Platform-Xbox                   0\n",
       "Platform-PlayStation            0\n",
       "Platform-Nintendo               0\n",
       "Platform-Sega                   0\n",
       "RatingsBreakdown-Recommended    0\n",
       "RatingsBreakdown-Meh            0\n",
       "RatingsBreakdown-Exceptional    0\n",
       "RatingsBreakdown-Skip           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 625
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Very good', 'Good', 'Bad', 'Very bad'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 626
    }
   ],
   "source": [
    "Labels = data['Metacritic'].unique()\n",
    "#Labels = ['Very good', 'Good', 'Bad', 'Very bad']\n",
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Presence 0.21990852622283635\nOriginalCost 0.334796531233014\nAchievements 0.13271676079289932\nStorage 0.12270640311751353\nRatingsBreakdown-Recommended 0.06823089092378383\nRatingsBreakdown-Meh 0.021279269492762667\nRatingsBreakdown-Exceptional 0.04326827691867334\nRatingsBreakdown-Skip 0.06685777973971664\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "exponential = ['Presence', 'OriginalCost', 'Achievements', 'Storage', 'RatingsBreakdown-Recommended', 'RatingsBreakdown-Meh', 'RatingsBreakdown-Exceptional', 'RatingsBreakdown-Skip']\n",
    "lambdas = {}\n",
    "\n",
    "for name in exponential:\n",
    "    boc = boxcox(data.loc[:,name].apply(lambda x: x + 1*10**(-10)))\n",
    "    data.loc[:,name] = boc[0]\n",
    "    print(name, boc[1])\n",
    "    lambdas[name] = boc[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "22.18866283 77.80781825 15.23562412 11.83785407 42.88607066\n 86.5195187  40.82301059 51.07066803 41.54069027 90.4092775  82.10263935\n 64.60555553 90.35513041 80.65733428 73.59955118 21.34397495 23.6380926\n 20.73575189 26.92993356 12.63516149 52.00283042 83.3954312   9.31586878\n 80.72631995 78.49698308 35.5372869  73.61761436 90.36957896 18.92744068\n 90.34983274 90.3446592  65.34174405 44.63631013 58.8080091  80.80583483\n 13.62934695 90.3712464  20.25088711 20.90880952 11.14063909 84.51178701\n 60.5250556  90.34764245 29.29575854 58.31207588 41.99633294 69.49023931\n 11.39301071 90.35540153 42.93359403 33.19973136 69.48258995 90.35037507\n 90.3607398   9.41058351 12.86256658 90.43501051 67.3698873  57.52855218\n 56.17349916 59.70015848 47.87466382 68.06815768 39.56671254 12.87110511\n 63.85533054 13.58515077 90.35135541 48.87837258 62.15697703 13.35822882\n 90.39328853 13.67316519 90.36797395 65.19563002 53.88004829 12.2629631\n 33.07104658 38.37010026 16.29753935 37.15614584 90.3542962  74.69419256\n 13.24874458 29.56208974 10.50264983 59.25040303 24.7733869  59.77937263\n 61.88299047 85.95450304 90.35329512 36.61173978 88.94762992 79.11685348\n 10.0492102  25.37767291 15.92977143 61.47627853 90.34693318 54.89259549\n 47.33439616 33.12978323 39.01126404 72.73777208 58.57404626 79.92221334\n 87.52394179 90.34367862 62.12030103 90.38762348 20.99489345 28.93734381\n 55.53766126 90.37316383 57.2263411  12.2532759  18.43590134 10.15951016\n 61.64510456 28.92137549 90.35905085 48.18810272 67.11782374 90.50864034\n 90.35097996 57.81712665 32.74948261 39.06696143 59.4251311  36.18768194\n 81.21350319 64.34901492 21.37110714 40.62713218 90.44717151 56.24380977\n 20.19216004 26.6484074  43.04720793 13.62200737 69.28667869 90.35064623\n 15.84748732 38.41250137 90.44771187 13.15296135 71.57827746 48.21506979\n 55.02573423 41.14816159 90.34636992 70.52048163 77.98698453 82.25668234\n 49.02097751 90.35490101 12.14538546 37.57940896 13.427377   20.91768626\n 87.5840823  49.68694022 13.26453188 88.54659033 14.07189966 50.09004328\n 90.34726696 90.35475502 38.94003926 90.35844614 52.06604111 90.36067724\n 44.3014446  49.52550253 57.35717951 83.04407627 51.2580456  73.97253978\n 11.20203801 56.59527307 10.58775632 90.37182998 48.64329192 22.41475396\n 54.46196588 70.03656503 90.50374627 12.50815099 90.35196028 85.17188755\n 83.69446042 12.35876311 25.20067181 54.99437415 11.88005201 12.7326691\n 35.53595606 90.35965555 62.74764165 56.02595593 90.34843515 42.12779239\n 68.97765689 90.35738265 62.40504293 59.8757224  58.26191979 61.87382279\n 90.35043765 84.34153323 74.31788273 12.07541818 20.18970233 90.38014461\n 42.84695058 49.32399082 12.11552703 90.35563093 18.56229434 70.72444875\n 90.37885278 12.28227831 90.35258599 10.8200892  59.57180222 47.63766871\n 24.90415746 90.3461613  90.36780719 59.42690533 50.26016236 90.35269028\n 37.8634709  57.8737237  39.98744634 80.49966496 61.58106308 90.35930107\n 90.38953974 90.35133455 41.1328235  83.07127727 11.41631965 37.77855848\n 40.57564865 81.70719482 82.48313738 72.60593432 90.35287799 82.26320615\n 52.00636325 45.11262749 87.00801514 27.16112581 90.3611151  90.35404594\n 90.35200199 86.59487478 51.57214854 33.40470791 54.15512059 56.25474133\n 46.48868679 37.73238726 45.02229063 49.4955606  13.23290743 45.62637912\n 54.29539264 55.14778469 88.76108823 80.36912213 40.90677831 18.24484762\n 29.2161842  90.36023938 17.95919669 19.55151133 25.5632846  46.44474431\n 78.25823202]\n\u001b[1mMemory\u001b[0;0m\n[2.56000000e+02 2.00000000e+03 6.00000000e+03 2.54547006e+03\n 4.00000000e+03 5.12000000e+02 1.00000000e+03 8.00000000e+03\n 2.04800000e+03 2.50000000e+03 1.50000000e+03 1.02400000e+03\n 3.00000000e+03 6.40000000e+01 7.68000000e+02 1.28000000e+02\n 2.00000000e+02 1.53600000e+03 3.00000000e+02 1.60000000e+01\n 8.19200000e+03 4.00000000e+00 4.09600000e+03 9.60000000e+01\n 8.00000000e+02 3.07200000e+03 5.00000000e+02 2.00000000e+00\n 4.00000000e+02 3.00000000e+00 3.20000000e+01 8.00000000e+00\n 5.00000000e+03 2.50000000e+02]\n\u001b[1mReleaseDate\u001b[0;0m\n[2008.         2014.         2016.         2017.         2013.\n 2018.         2015.         2007.         2009.         2020.\n 2019.         2012.         2010.         2006.         2004.\n 1999.         2002.         2011.         2005.         2001.\n 1994.         1993.         1998.         2003.         1996.\n 2000.         2012.59938838 1997.        ]\n\u001b[1mSoundtrack\u001b[0;0m\n[False  True]\n\u001b[1mOriginalCost\u001b[0;0m\n[ 5.15502805  4.40700758  7.28255269  3.46772274 -2.98554831  6.33933105\n  4.23806124  2.12923086  2.45185819  4.06087812  8.77599174 -0.01003345\n  3.00258381  2.74037361  5.78688323  8.07932948  1.76014904  3.87437271\n  4.37789628  1.32306006  3.24377745  6.83344224  0.77385741  3.67721064\n  4.56861349  4.12924231  4.87268746  7.69570099  4.72362871  0.26581192\n  2.87439205  5.41915024  6.01597776  9.56168149  5.01633156  4.40865862\n  9.39910054]\n\u001b[1mDiscountedCost\u001b[0;0m\n[ 0.    0.99 19.99  7.49  1.49  0.49  1.99  4.99  4.49  3.74  0.69  0.5\n  8.99  1.79  3.89  0.59  1.74]\n\u001b[1mController\u001b[0;0m\n[False  True]\n\u001b[1mAchievements\u001b[0;0m\n[-7.18010623e+00  5.92131682e+00  5.12872279e+00  6.99669613e+00\n  5.55048373e+00  4.67578433e+00  8.13591605e+00  7.98063440e+00\n  5.52316303e+00  4.54323762e+00  7.16778202e+00  3.75154239e+00\n  4.79954666e+00  8.16909561e+00  5.63028083e+00  6.03136057e+00\n  3.35147753e+00  8.71962818e+00  5.09481424e+00  4.35025885e+00\n  5.38064043e+00  5.80505764e+00  5.06030011e+00  3.16025119e+00\n  6.68898253e+00  3.82143992e+00  7.27902908e+00  3.25863065e+00\n  2.02273663e+00  4.24552723e+00  7.89901797e+00  4.58847903e+00\n  2.69316298e+00  7.77590882e+00  4.63264336e+00  5.22703309e+00\n  6.07379258e+00  8.43410628e+00  6.05268481e+00  4.75919150e+00\n  6.55933638e+00  3.52298714e+00  5.87560092e+00  6.57597327e+00\n  6.36728416e+00  5.25873153e+00  5.94379950e+00  4.29865012e+00\n  3.67869607e+00  2.55113896e+00  7.11651904e+00  4.95287908e+00\n  3.43942113e+00  3.05557658e+00  7.71683462e+00  2.82336140e+00\n  3.95334091e+00  6.33043096e+00  4.91568963e+00  4.01575007e+00\n  5.98804314e+00  5.60403236e+00  6.38547398e+00  6.00981502e+00\n  5.02515663e+00  3.88863426e+00  5.40997529e+00  4.07603050e+00\n  5.89858595e+00  5.65619170e+00  2.94366990e+00  6.21585984e+00\n  4.44928574e+00  4.49686091e+00  6.50864093e+00  6.17624266e+00\n  5.96603975e+00  1.79424621e+00  4.19079118e+00  5.28992490e+00\n  5.35086361e+00  1.00000008e-10  5.43888205e+00  5.70703709e+00\n  7.43066228e+00  4.40044338e+00  7.58345890e+00  4.83905702e+00\n  5.19481162e+00  8.57751736e+00  6.92723134e+00  4.13433264e+00\n  7.82402417e+00  6.54257016e+00  6.09468853e+00  4.98935857e+00\n  7.93563968e+00  5.75663781e+00  6.87004612e+00  6.25474488e+00\n  5.78099154e+00  6.70465714e+00  7.19298181e+00  6.49147337e+00\n  6.84088778e+00  7.26029803e-01  5.82884332e+00  4.87775977e+00\n  5.85235552e+00  6.98297601e+00  6.65729042e+00  6.94129948e+00\n  1.52201717e+00  8.48525911e+00  6.91307319e+00  7.12944492e+00\n  6.11537721e+00  6.29292630e+00  6.47416740e+00  7.09044146e+00\n  5.32063021e+00  5.16204819e+00  6.40350979e+00  7.46426989e+00\n  8.72619646e+00  6.85551521e+00  7.88049203e+00  7.55155901e+00\n  7.60448367e+00  6.89882380e+00  6.19614462e+00  6.52567242e+00\n  7.10351819e+00  6.43913043e+00  3.60261936e+00  5.73198893e+00\n  2.22028307e+00  6.31176161e+00  6.34893747e+00  6.82616243e+00\n  7.80489624e+00  7.45312200e+00  7.56224131e+00  6.45672058e+00\n  4.71795167e+00  7.67660479e+00  7.05074618e+00  6.13586299e+00\n  6.78138452e+00  6.64126929e+00  8.79094400e+00  7.62531935e+00\n  5.49546360e+00  2.39470295e+00  7.25477643e+00  7.37352923e+00\n  7.21790295e+00  5.57743668e+00  7.20547680e+00  6.60886751e+00\n  7.88977318e+00  7.70684206e+00  7.33855011e+00  7.73669234e+00\n  7.03735607e+00  7.29105876e+00  8.02479225e+00  7.81447968e+00\n  7.23026107e+00  6.23539205e+00  6.67319422e+00  7.06405644e+00\n  8.35912085e+00  6.42139437e+00  7.53004492e+00  7.50832817e+00\n  7.79527352e+00  8.25009592e+00  7.41934930e+00  7.30302500e+00\n  5.46737395e+00  6.59248295e+00  6.72021981e+00  7.86181944e+00\n  7.15507552e+00  6.62512897e+00  7.47536390e+00  8.33616739e+00\n  7.64596956e+00  7.02388506e+00  7.48640459e+00  6.73567223e+00\n  8.59832557e+00  7.84299769e+00  7.68672754e+00  6.27392183e+00\n  7.18041717e+00  8.12754897e+00  6.88448188e+00  6.15615011e+00]\n\u001b[1mStorage\u001b[0;0m\n[12.56095209 10.87228235 13.13586381 23.22280251 13.61742791 16.0782557\n 15.02548395 20.72428436 16.7587409  18.37000145 16.40133721 11.30263483\n  7.76039452  7.89678303 15.5497991   9.32130157  7.46337719 14.03307463\n  8.25981736 14.3995342  22.19718513 17.08285592  5.02111796 16.00234504\n  8.84941994  5.3190928  11.09605167 11.49463054  7.31473028 23.88787074\n 20.95385231 18.7804407  22.74037167 17.37968534  6.921849    6.19034813\n 19.79807823  5.80303254  6.65951467  9.8929054   2.90537634 20.08549085\n 10.75293472 12.91919349 17.65371736  7.94354855  7.39527147  8.57315889\n 18.14643825 22.59206705  3.62049374 10.35850923 24.41713282 24.66030055\n  8.71533194 14.8800781  17.90839918 19.32287194  8.39028369  5.17605521\n 10.21251751 21.76174633  9.71656443 10.05772298 11.84261635 10.62794337\n  9.58528421 10.04171456  9.09688525  7.81660608 21.57407549 19.1505032\n  5.57628031 20.22170316 18.58085113 12.29492182 10.92771969 14.19962865\n 10.4723652  19.48783887  9.37221872  4.22090213  8.68198637 10.44230492\n 22.43846371 11.67407987  7.5662885  22.95370587 14.72779628 21.37753004\n  2.66080165 14.85019373 23.09032549 23.28756973 10.82518563  6.35903999\n 16.58465286  6.79479524 12.00156855 18.96998348 25.32116561 21.27563866\n 10.49670449 14.57183582 18.0293528  15.29811081  6.58841538 21.17116053\n 21.47696797 20.48087425 21.94135827  9.40972399  5.69297449  8.23959316\n 14.90968777 10.52348439 13.18764829 14.78957863]\n\u001b[1mPlatform-Mobile\u001b[0;0m\n[ True False]\n\u001b[1mPlatform-PC\u001b[0;0m\n[ True False]\n\u001b[1mPlatform-Xbox\u001b[0;0m\n[False  True]\n\u001b[1mPlatform-PlayStation\u001b[0;0m\n[False  True]\n\u001b[1mPlatform-Nintendo\u001b[0;0m\n[False  True]\n\u001b[1mPlatform-Sega\u001b[0;0m\n[False  True]\n\u001b[1mRatingsBreakdown-Recommended\u001b[0;0m\n[2.70798893e+00 7.09799530e-01 1.45397483e+00 4.16210929e+00\n 5.57884085e+00 3.59971466e+00 3.12559433e+00 6.06475384e+00\n 5.15729819e+00 6.44592981e+00 5.70750185e+00 1.00000008e-10\n 2.97438521e+00 5.10759231e+00 5.89670611e+00 2.89158563e+00\n 5.11687478e+00 4.05961583e+00 8.75763837e+00 2.80308044e+00\n 4.34674848e+00 5.14091826e+00 3.49614843e+00 4.58461991e+00\n 2.60520600e+00 5.12435113e+00 5.91632891e+00 7.55234346e+00\n 1.90588682e+00 3.19507787e+00 4.80896334e+00 3.90981069e+00\n 5.97370965e+00 4.60872398e+00 7.91656278e+00 1.70113231e+00\n 6.09103385e+00 4.31763289e+00 7.40906930e+00 6.74001619e+00\n 4.48384929e+00 5.34069558e+00 3.78552762e+00 5.20535742e+00\n 7.16269109e+00 2.23419073e+00 1.14083629e+00 4.88964687e+00\n 5.18951366e+00 3.54893705e+00 5.54172518e+00 4.50972775e+00\n 6.68192505e+00 7.34020946e+00 2.49331811e+00 5.32626255e+00\n 4.09463681e+00 6.04697754e+00 4.28789408e+00 5.41080278e+00\n 4.02367642e+00 5.74074395e+00 5.42443124e+00 3.05219269e+00\n 4.45748400e+00 4.67866122e+00 6.67004328e+00 6.46646002e+00\n 5.36914183e+00 2.08100261e+00 5.46457506e+00 4.82956566e+00\n 4.65573113e+00 3.74142538e+00 3.64863387e+00 7.82047688e+00\n 6.34633668e+00 6.36822661e+00 6.59052427e+00 5.94529208e+00\n 6.15897082e+00 2.37047560e+00 5.55420076e+00 7.93566956e+00\n 6.19994280e+00 3.44117632e+00 6.35366798e+00 3.69583037e+00\n 3.98676719e+00 4.72343690e+00 4.19464505e+00 5.77326228e+00\n 5.02075374e+00 6.68783222e+00 7.97323376e+00 6.40403223e+00\n 5.52914347e+00 7.50362439e+00 7.41281006e+00 8.07110260e+00\n 5.60307790e+00 5.78394647e+00 8.12281508e+00 7.34800738e+00\n 6.51333038e+00 5.07348083e+00 5.85667563e+00 5.83625324e+00\n 5.28208869e+00 4.40321424e+00 6.74570848e+00 6.38264886e+00\n 6.03801062e+00 3.86963592e+00 4.25750375e+00 7.80879530e+00\n 5.03854443e+00 7.42026571e+00 7.16705088e+00 5.43793454e+00\n 7.54202594e+00 4.12878671e+00 6.89208462e+00 7.29663239e+00\n 4.98449928e+00 7.27642741e+00 3.38382472e+00 5.38316061e+00\n 5.29696216e+00 7.10490302e+00 7.83207613e+00 5.49074243e+00\n 6.65807042e+00 5.39704674e+00 6.19183594e+00 6.45280355e+00\n 6.89725309e+00 5.45131505e+00 6.58423591e+00 4.37526732e+00\n 5.22103043e+00 4.86989908e+00 4.22643157e+00 5.92604526e+00\n 5.09063716e+00 3.32386967e+00 7.14513198e+00 7.28048879e+00\n 6.57792204e+00 8.20789937e+00 4.94730723e+00 8.62430679e+00\n 6.76827318e+00 7.27235574e+00 6.82330530e+00 4.92834362e+00\n 7.39779477e+00 5.66199368e+00 5.80508876e+00 6.21602858e+00\n 6.38980967e+00 6.23984425e+00 3.94883225e+00 4.76684291e+00\n 6.02899033e+00 7.91381512e+00 7.45703693e+00 4.43061251e+00\n 5.95482417e+00 6.47324329e+00 6.27103268e+00 6.79051793e+00\n 6.63993712e+00 8.38280810e+00 5.68492156e+00 6.16725373e+00\n 7.96258780e+00 6.59678730e+00 4.56009628e+00 6.48672129e+00\n 3.26105353e+00 6.92791361e+00 7.57616620e+00 6.08232428e+00\n 5.88679795e+00 6.50008296e+00 5.31168575e+00 8.72738781e+00\n 3.82823498e+00 5.05611832e+00 4.53513766e+00 4.70122585e+00\n 5.96429644e+00 7.70287471e+00 6.90753955e+00 7.47870533e+00\n 5.87682409e+00 6.70542096e+00 7.56939521e+00 5.63870694e+00\n 6.07356448e+00 7.45339718e+00 6.83944613e+00 5.00274064e+00\n 8.32793365e+00 6.99722453e+00 4.90912589e+00 6.85011545e+00\n 5.25187921e+00 6.95799064e+00 5.79455492e+00 6.71703786e+00\n 7.00688310e+00 7.26418129e+00 5.71866503e+00 6.84478983e+00\n 6.69371715e+00 8.04081503e+00 4.78805887e+00 8.01514684e+00\n 7.38263856e+00 5.65039590e+00 6.18368579e+00 6.26329492e+00\n 4.63242310e+00 6.43208990e+00 5.67350176e+00 7.53164250e+00\n 6.23194683e+00 6.53299165e+00 7.51067438e+00 7.63912490e+00\n 7.84646124e+00 7.47151468e+00 4.84987473e+00 5.47771680e+00\n 7.44974923e+00 5.62692532e+00 6.22400842e+00 8.92572348e+00\n 7.74606680e+00 5.26706214e+00 6.10830462e+00 6.09969376e+00\n 7.18437206e+00 6.01078695e+00 5.59100890e+00]\n\u001b[1mRatingsBreakdown-Meh\u001b[0;0m\n[2.24940055e+00 1.00000008e-10 3.62987003e+00 4.05751325e+00\n 1.11155444e+00 2.12613430e+00 4.60647001e+00 3.28797833e+00\n 4.94359562e+00 4.01226256e+00 6.98284251e-01 3.14530711e+00\n 4.18315397e+00 2.71456518e+00 2.98110860e+00 6.74480219e+00\n 3.03863871e+00 3.63303818e+00 2.46012606e+00 2.78759695e+00\n 3.33167545e+00 1.98675971e+00 4.07946499e+00 4.83836593e+00\n 1.63731499e+00 1.82635526e+00 5.42036207e+00 3.56256532e+00\n 2.92036124e+00 5.06719728e+00 4.20278015e+00 2.35992807e+00\n 4.50732167e+00 4.44645797e+00 3.24246162e+00 2.85601073e+00\n 4.56504693e+00 1.40694429e+00 3.66203908e+00 4.39853320e+00\n 4.61994461e+00 3.91581222e+00 4.84934188e+00 4.36540202e+00\n 3.45318510e+00 3.96508660e+00 5.49692847e+00 5.10266282e+00\n 4.49241323e+00 4.24102404e+00 4.86021197e+00 3.09327844e+00\n 4.10099118e+00 5.72548809e+00 3.72368908e+00 5.08506890e+00\n 2.55177728e+00 5.24980893e+00 3.89032741e+00 3.78207402e+00\n 3.75326770e+00 6.44561817e+00 4.75838535e+00 3.19496527e+00\n 3.52730204e+00 5.80361806e+00 4.47730355e+00 5.71533665e+00\n 3.49086904e+00 3.41416021e+00 4.90267388e+00 3.98892554e+00\n 4.14283139e+00 5.02124308e+00 5.90736213e+00 5.16217516e+00\n 3.94072345e+00 4.74648115e+00 5.01182389e+00 3.59673239e+00\n 4.41473749e+00 3.37369427e+00 4.92332018e+00 2.63623821e+00\n 5.74054865e+00 4.80478162e+00 6.45102063e+00 4.70999338e+00\n 5.00232557e+00 3.81014777e+00 4.96351342e+00 4.31378565e+00\n 4.53655603e+00 4.77016493e+00 3.83752565e+00 4.43071022e+00\n 4.73444962e+00 5.17042750e+00 4.72228799e+00 5.03058447e+00\n 4.03511859e+00 5.48451903e+00 4.64641795e+00 5.59729476e+00\n 6.64653432e+00 4.33125771e+00 5.93295361e+00 6.15481140e+00\n 3.69329513e+00 3.86424167e+00 5.20284930e+00 4.93350342e+00\n 4.81608800e+00 5.15386232e+00 5.68955750e+00 4.82728203e+00\n 5.03984934e+00 5.13705152e+00 4.34846041e+00 5.17862023e+00\n 4.91304425e+00 4.12210817e+00 5.95798831e+00 5.23437052e+00\n 5.61412643e+00 4.99274678e+00 4.59283161e+00 5.12855169e+00\n 4.65942415e+00 5.45289170e+00 5.37320170e+00 5.07616835e+00\n 6.24192333e+00 4.52203423e+00 4.16317540e+00 4.67228144e+00\n 5.14548808e+00 5.50920444e+00 4.57902533e+00 4.27799840e+00\n 5.72042361e+00 4.89220732e+00 5.52737435e+00 5.66850814e+00\n 5.24211595e+00 4.29603558e+00 5.30954664e+00 4.88164274e+00\n 4.98308611e+00 5.21081204e+00 5.57446002e+00 5.05815453e+00]\n\u001b[1mRatingsBreakdown-Exceptional\u001b[0;0m\n[1.12514229e+00 4.38075677e+00 1.86304393e+00 4.62923825e+00\n 3.01419181e+00 2.17585910e+00 3.54241928e+00 3.19855373e+00\n 4.30910276e+00 5.85694649e+00 1.00000008e-10 4.86953212e+00\n 4.02856280e+00 7.03646063e-01 1.42871502e+00 6.78691782e+00\n 2.79563350e+00 3.77485528e+00 2.62341139e+00 3.99958153e+00\n 3.40692867e+00 5.25640618e+00 2.03017756e+00 4.23869056e+00\n 4.39716910e+00 3.93947839e+00 2.52670547e+00 7.62048356e+00\n 6.65984084e+00 6.41706221e+00 5.27776146e+00 3.49892985e+00\n 2.71269431e+00 5.78737780e+00 7.03273733e+00 5.46469745e+00\n 3.84339349e+00 4.13810017e+00 2.42119310e+00 3.80960661e+00\n 4.26260891e+00 2.94575040e+00 4.45935378e+00 5.04625333e+00\n 2.30505984e+00 1.66680038e+00 3.58439417e+00 3.73908146e+00\n 5.74378733e+00 6.17974224e+00 4.57513306e+00 4.43896854e+00\n 3.70222166e+00 4.53771913e+00 6.06341419e+00 5.24559376e+00\n 5.26712823e+00 7.04114430e+00 3.25415492e+00 2.87308746e+00\n 6.61083845e+00 5.62797494e+00 6.03413863e+00 5.65197630e+00\n 6.58760523e+00 7.77483706e+00 5.93582851e+00 3.45380970e+00\n 7.08512688e+00 5.35980076e+00 4.33171176e+00 6.98117629e+00\n 3.30727848e+00 4.76306405e+00 5.58696048e+00 4.59342890e+00\n 3.14022640e+00 6.76655177e+00 5.23468940e+00 6.12562222e+00\n 5.32964602e+00 6.56793243e+00 3.87626914e+00 6.38564119e+00\n 3.62495861e+00 5.71389664e+00 5.54460750e+00 6.65613413e+00\n 6.88438976e+00 5.63602472e+00 6.97532487e+00 3.35814019e+00\n 7.35883640e+00 6.80365830e+00 4.79441043e+00 6.37652617e+00\n 6.39469436e+00 4.41824423e+00 4.88403541e+00 7.46129445e+00\n 3.07888473e+00 5.87042739e+00 4.73091831e+00 4.05687553e+00\n 6.62610712e+00 4.91255297e+00 7.52953173e+00 5.96110333e+00\n 5.82262442e+00 5.03349859e+00 4.11161646e+00 5.30914287e+00\n 5.33977632e+00 5.82956119e+00 7.31150030e+00 4.51858391e+00\n 6.85907524e+00 5.90353536e+00 4.66405380e+00 4.80979635e+00\n 7.45923562e+00 3.66420625e+00 5.15564358e+00 5.69869033e+00\n 7.46335021e+00 5.19011971e+00 4.74709370e+00 4.94044296e+00\n 6.35810703e+00 6.80698167e+00 7.02710375e+00 4.77883461e+00\n 7.00720076e+00 6.70712222e+00 7.45304070e+00 5.42753243e+00\n 6.16909380e+00 5.40854084e+00 4.99444885e+00 6.80032674e+00\n 6.10894482e+00 3.96989861e+00 6.66722378e+00 3.90828242e+00\n 7.29767120e+00 4.89837444e+00 5.21259839e+00 7.02144678e+00\n 6.26198413e+00 5.48288663e+00 7.62962396e+00 6.53177790e+00\n 4.85486068e+00 6.98700265e+00 4.84001706e+00 4.21430056e+00\n 7.26722232e+00 6.11452737e+00 5.61172423e+00 4.82499706e+00\n 5.17873059e+00 4.35391626e+00 5.80863955e+00 6.00419806e+00\n 6.98409258e+00 5.37951856e+00 5.69102011e+00 7.57953570e+00\n 5.67554282e+00]\n\u001b[1mRatingsBreakdown-Skip\u001b[0;0m\n[2.07816350e+00 7.09459194e-01 1.00000008e-10 3.25424998e+00\n 4.01347509e+00 3.77645553e+00 3.93899240e+00 3.68716768e+00\n 2.36681411e+00 2.94825616e+00 2.96869212e+00 2.23092883e+00\n 1.45257007e+00 5.60757688e+00 1.13996550e+00 1.69921964e+00\n 1.90349653e+00 3.11932705e+00 3.81896489e+00 5.10815274e+00\n 3.97674487e+00 2.48927769e+00 2.70324402e+00 3.04620737e+00\n 2.79800641e+00 3.64018307e+00 4.15122354e+00 2.60080507e+00\n 2.88619594e+00 4.70956854e+00 4.54712982e+00 4.66504284e+00\n 3.31681046e+00 4.11806757e+00 4.89419877e+00 5.36537154e+00\n 4.21522086e+00 3.37651740e+00 5.44627174e+00 3.54092582e+00\n 3.73255568e+00 4.57151981e+00 4.68748175e+00 4.27636877e+00\n 3.18853808e+00 4.08408720e+00 4.52230658e+00 3.59148091e+00\n 4.18359548e+00 4.79461173e+00 5.57189391e+00 4.59549191e+00\n 3.48836553e+00 4.04923878e+00 5.05758717e+00 4.39108787e+00\n 3.43362791e+00 4.75273023e+00 6.24728386e+00 5.51042761e+00\n 4.24613449e+00 5.39283984e+00 3.90015691e+00 5.20424571e+00\n 3.86017201e+00 4.30595392e+00 4.64223997e+00 4.85519857e+00\n 4.98726635e+00 5.84584362e+00 4.61906069e+00 5.14090105e+00\n 4.47129434e+00 4.87483247e+00 5.15700001e+00 4.41834128e+00\n 5.04032806e+00 4.49703382e+00 4.73131445e+00]\n"
     ]
    }
   ],
   "source": [
    "for name in data.columns:\n",
    "    print('\\033[1m'+name+'\\033[0;0m')\n",
    "    print(data[name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"import matplotlib.pyplot as plt\\ncols = ['Presence', 'Memory', 'ReleaseDate', 'OriginalCost', 'DiscountedCost', 'Achievements', 'Storage', 'RatingsBreakdown-Recommended', 'RatingsBreakdown-Meh', 'RatingsBreakdown-Exceptional', 'RatingsBreakdown-Skip']\\n\\nfor name in cols:\\n    fig, axes= plt.subplots(1,2, gridspec_kw={'width_ratios': [1, 4]}, figsize=(9,5))\\n    data.boxplot(column=name,ax=axes[0])\\n    data.hist(column=name, ax=axes[1])\\nplt.show()\""
      ]
     },
     "metadata": {},
     "execution_count": 629
    }
   ],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "cols = ['Presence', 'Memory', 'ReleaseDate', 'OriginalCost', 'DiscountedCost', 'Achievements', 'Storage', 'RatingsBreakdown-Recommended', 'RatingsBreakdown-Meh', 'RatingsBreakdown-Exceptional', 'RatingsBreakdown-Skip']\n",
    "\n",
    "for name in cols:\n",
    "    fig, axes= plt.subplots(1,2, gridspec_kw={'width_ratios': [1, 4]}, figsize=(9,5))\n",
    "    data.boxplot(column=name,ax=axes[0])\n",
    "    data.hist(column=name, ax=axes[1])\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3, 1, 0, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 631
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "Labels_encoded = encoder.fit_transform(Labels)\n",
    "Labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"from sklearn.preprocessing import LabelBinarizer\\n\\nOneHot = LabelBinarizer().fit_transform(data.loc[:,'Metacritic'])\\nindex = [x for x in range(data.shape[0])]\\nfor i in data.index:\\n    data['Metacritic'].update(pd.Series([OneHot[i]], index=[i])) \""
      ]
     },
     "metadata": {},
     "execution_count": 632
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "OneHot = LabelBinarizer().fit_transform(data.loc[:,'Metacritic'])\n",
    "index = [x for x in range(data.shape[0])]\n",
    "for i in data.index:\n",
    "    data['Metacritic'].update(pd.Series([OneHot[i]], index=[i])) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_expected = encoder.fit_transform(data['Metacritic'])\n",
    "#data_expected = data[Labels] \n",
    "#data_expected = data['Metacritic']\n",
    "data_input = data.loc[:, data.columns != 'Metacritic']\n",
    "#data_input = data.loc[:, data.columns.difference(Labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_input, data_expected, test_size=0.3,random_state=404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "bnb = BernoulliNB()\n",
    "mnb = MultinomialNB(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "metadata": {},
     "execution_count": 638
    }
   ],
   "source": [
    "data['Metacritic'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-639-d07c370972b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "hist = bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Very good', 'Very bad', 'Bad', 'Very good', 'Very good',\n",
       "       'Very bad', 'Very good', 'Very good', 'Very good', 'Very bad',\n",
       "       'Very good', 'Very good', 'Very bad', 'Very bad', 'Very good',\n",
       "       'Very bad', 'Very good', 'Very bad', 'Very bad', 'Bad', 'Bad',\n",
       "       'Very good', 'Bad', 'Bad', 'Very bad', 'Very good', 'Very bad',\n",
       "       'Very bad', 'Very bad', 'Very bad', 'Very good', 'Good', 'Bad',\n",
       "       'Very bad', 'Very good', 'Very good', 'Very bad', 'Very good',\n",
       "       'Very bad', 'Very bad', 'Very bad', 'Very bad', 'Very bad',\n",
       "       'Very good', 'Very good', 'Bad', 'Good', 'Very good', 'Very good',\n",
       "       'Bad', 'Good', 'Bad', 'Bad', 'Bad', 'Bad', 'Bad', 'Very bad',\n",
       "       'Very good', 'Very good', 'Very good', 'Very good', 'Very bad',\n",
       "       'Very good', 'Very bad', 'Very bad', 'Very good', 'Very good',\n",
       "       'Very bad', 'Very good', 'Bad', 'Very good', 'Very good', 'Good',\n",
       "       'Very good', 'Very bad', 'Bad', 'Very bad', 'Bad', 'Very bad',\n",
       "       'Very bad', 'Bad', 'Very bad', 'Very good', 'Very good',\n",
       "       'Very good', 'Very bad', 'Bad', 'Very good', 'Very good',\n",
       "       'Very good', 'Very bad', 'Bad', 'Bad', 'Very good', 'Very bad',\n",
       "       'Bad', 'Very good', 'Bad', 'Bad', 'Very good', 'Very good', 'Good',\n",
       "       'Very good', 'Bad', 'Very good', 'Good', 'Good', 'Very good',\n",
       "       'Very good', 'Very bad', 'Bad', 'Very bad', 'Very bad', 'Bad',\n",
       "       'Very bad', 'Very good', 'Bad', 'Very good', 'Very bad', 'Bad',\n",
       "       'Very good', 'Good', 'Bad', 'Very bad', 'Bad', 'Very bad',\n",
       "       'Very bad', 'Very good', 'Very good', 'Very good', 'Very good',\n",
       "       'Very bad', 'Very good', 'Very good', 'Very good', 'Very bad',\n",
       "       'Very bad', 'Bad', 'Bad', 'Very good', 'Very good', 'Bad',\n",
       "       'Very good', 'Very good', 'Very good', 'Very good', 'Good', 'Bad',\n",
       "       'Very bad', 'Very bad', 'Very bad', 'Bad', 'Very good', 'Very bad',\n",
       "       'Good', 'Bad', 'Very bad', 'Very good', 'Very bad', 'Bad', 'Bad',\n",
       "       'Bad', 'Very bad', 'Bad', 'Very bad', 'Very bad', 'Very good',\n",
       "       'Very good', 'Bad', 'Very bad', 'Very good', 'Very good', 'Good',\n",
       "       'Bad', 'Very bad', 'Very good', 'Very good', 'Good', 'Bad', 'Bad',\n",
       "       'Very good', 'Very good', 'Bad', 'Bad', 'Very good', 'Bad', 'Bad',\n",
       "       'Very good', 'Bad', 'Very bad', 'Very bad', 'Bad', 'Very good',\n",
       "       'Bad', 'Bad', 'Very bad', 'Very bad', 'Very good', 'Very bad',\n",
       "       'Bad', 'Very good', 'Very good', 'Very good', 'Very good',\n",
       "       'Very good', 'Bad', 'Very bad', 'Very good', 'Very bad',\n",
       "       'Very good', 'Very bad', 'Very good', 'Very bad', 'Very good',\n",
       "       'Very good', 'Very good', 'Very good', 'Very good', 'Very bad',\n",
       "       'Bad', 'Very good', 'Very good', 'Very bad', 'Bad', 'Very bad',\n",
       "       'Very bad', 'Very good', 'Very good', 'Bad', 'Very good', 'Bad',\n",
       "       'Very bad', 'Very good', 'Good', 'Very bad', 'Very good',\n",
       "       'Very bad', 'Very good', 'Very good', 'Bad', 'Very bad',\n",
       "       'Very good', 'Very good', 'Very bad', 'Very good', 'Very bad',\n",
       "       'Bad', 'Very bad', 'Good', 'Bad', 'Bad', 'Bad', 'Very good',\n",
       "       'Very good', 'Very good', 'Bad', 'Bad', 'Bad', 'Very good', 'Good',\n",
       "       'Bad', 'Very good', 'Bad', 'Very bad', 'Bad', 'Very bad',\n",
       "       'Very good', 'Bad', 'Bad', 'Very good', 'Very good', 'Very good',\n",
       "       'Very bad', 'Bad', 'Very bad', 'Very good', 'Bad', 'Very good',\n",
       "       'Very good', 'Very good', 'Good', 'Good', 'Very good', 'Very bad',\n",
       "       'Very good', 'Very good', 'Very good', 'Bad', 'Bad', 'Very bad',\n",
       "       'Very bad', 'Very bad', 'Very bad', 'Very bad', 'Very bad',\n",
       "       'Very good'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 618
    }
   ],
   "source": [
    "encoder.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2635135135135135"
      ]
     },
     "metadata": {},
     "execution_count": 620
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 3, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 1 3]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-621-d1f2aa17b08d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   2224\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2226\u001b[1;33m             raise ValueError(\"y_true and y_pred contain different number of \"\n\u001b[0m\u001b[0;32m   2227\u001b[0m                              \u001b[1;34m\"classes {0}, {1}. Please provide the true \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2228\u001b[0m                              \u001b[1;34m\"labels explicitly through the labels argument. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 3, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 1 3]"
     ]
    }
   ],
   "source": [
    "log_loss(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}