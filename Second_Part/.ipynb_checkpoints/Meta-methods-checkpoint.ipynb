{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                     # Llibreria matemÃ tica\n",
    "import matplotlib.pyplot as plt        # Per mostrar plots\n",
    "import sklearn                         # Llibreia de DM\n",
    "import sklearn.datasets as ds            # Per carregar mÃ©s facilment el dataset digits\n",
    "import sklearn.model_selection as cv    # Pel Cross-validation\n",
    "import sklearn.neighbors as nb           # Per fer servir el knn\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('games_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = data.columns.get_loc('Metacritic')\n",
    "y = data.iloc[:,column]\n",
    "X = data.loc[:, data.columns != 'Metacritic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, data.columns != 'Metacritic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv=100\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "\n",
    "clf2 = KNeighborsClassifier(n_neighbors=5,weights='distance')\n",
    "\n",
    "clf3 = DecisionTreeClassifier(max_depth=13, criterion='entropy')\n",
    "\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3], ['Naive Bayes','Knn (3)', 'Dec. Tree', ]):\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f [%s]\" % (scores.mean(), label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('nb', clf1), ('knn3', clf2), ('dt', clf3)], voting='hard')\n",
    "scores = cross_val_score(eclf, X, y, cv=cv, scoring='accuracy')\n",
    "print(\"Accuracy: %0.3f [%s]\" % (scores.mean() , \"Majority Voting\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('nb', clf1), ('knn3', clf2), ('dt', clf3)],voting='soft', weights=[1,1,2])\n",
    "scores = cross_val_score(eclf, X, y, cv=cv, scoring='accuracy')\n",
    "print(\"Accuracy: %0.3f [%s]\" % (scores.mean(), \"Weighted Voting\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "import time\n",
    "\n",
    "lb=[]\n",
    "lb_time=[]\n",
    "for nest in [1,2,5,10,20,50,100]:\n",
    "    start = time.time()\n",
    "    scores = cross_val_score(BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=13, criterion='entropy'),n_estimators=nest), X, y, cv=cv, scoring='accuracy')\n",
    "    lb_time.append(time.time() - start)\n",
    "    print(\"Accuracy: %0.3f [%s]\" % (scores.mean(), nest))\n",
    "    lb.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb2=[]    \n",
    "lb2_time=[]\n",
    "for nest in [1,2,5,10,20,50,100]:\n",
    "    start = time.time()\n",
    "    scores = cross_val_score(BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=13, criterion='entropy'),n_estimators=nest,max_features=0.35), X, y, cv=cv, scoring='accuracy')\n",
    "    lb2_time.append(time.time()  - start)\n",
    "    print(\"Accuracy: %0.3f [%s]\" % (scores.mean(), nest))\n",
    "    lb2.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,2,5,10,20,50,100],lb,label=\"Bagging DT\")\n",
    "plt.show()\n",
    "plt.plot([1,2,5,10,20,50,100],lb2,label=\"Bagging DT forced variance\")\n",
    "plt.show()\n",
    "plt.plot([1,2,5,10,20,50,100],lb_time,label=\"Bagging DT\", color = \"red\")\n",
    "plt.show()\n",
    "plt.plot([1,2,5,10,20,50,100],lb2_time,label=\"Bagging DT forced variance\", color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "lrf=[]\n",
    "for nest in [1,2,5,10,20,50,100]:\n",
    "    scores = cross_val_score(RandomForestClassifier(n_estimators=nest, max_depth=13,n_jobs=-1), X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    print(\"Accuracy: %0.3f [%s]\" % (scores.mean(), nest))\n",
    "    lrf.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "lext=[]\n",
    "for nest in [1,2,5,10,20,50,100]:\n",
    "    scores = cross_val_score(ExtraTreesClassifier(n_estimators=nest, max_depth=13, n_jobs=-1), X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    print(\"Accuracy: %0.3f [%s]\" % (scores.mean(), nest))\n",
    "    lext.append(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "lboo=[]\n",
    "for nest in [1,2,5,10,20,50,100]:\n",
    "    scores = cross_val_score(AdaBoostClassifier(n_estimators=nest), X, y, cv=cv, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f [%s]\" % (scores.mean(), nest))\n",
    "    lboo.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "lboodt=[]\n",
    "for nest in [1,2,5,10,20,50,100]:\n",
    "    scores = cross_val_score(AdaBoostClassifier(DecisionTreeClassifier(max_depth=13, criterion='entropy'),n_estimators=nest), X, y, cv=cv, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f [%s]\" % (scores.mean(), nest))\n",
    "    lboodt.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "lgbboo=[]\n",
    "for nest in [1,2,5,10,20,50,100]:\n",
    "    scores = cross_val_score(GradientBoostingClassifier(n_estimators=nest), X, y, cv=cv, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f [%s]\" % (scores.mean(), nest))\n",
    "    lgbboo.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot([1,2,5,10,20,50,100],lb,label=\"Bagging DT\")\n",
    "plt.plot([1,2,5,10,20,50,100],lb2,label=\"Bagging DT forced variance\")\n",
    "plt.plot([1,2,5,10,20,50,100],lrf,label=\"Random Forest\")\n",
    "plt.plot([1,2,5,10,20,50,100],lext,label=\"Extra Trees\")\n",
    "plt.plot([1,2,5,10,20,50,100],lboo,label=\"AdaBoost Dec.Stumps\")\n",
    "plt.plot([1,2,5,10,20,50,100],lboodt,label=\"AdaBoost DT\")\n",
    "plt.plot([1,2,5,10,20,50,100],lgbboo,label=\"Gradient Boosting\")\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
